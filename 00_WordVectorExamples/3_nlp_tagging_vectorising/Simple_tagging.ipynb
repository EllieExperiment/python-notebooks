{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "We will use two popular libraries to make our job much easier. [NLTK](http://www.nltk.org/) is a NLP Swiss army knife and [Gensim](https://radimrehurek.com/gensim/apiref.html) is more focused on topic modelling and vector models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data location\n",
    "DATA_FILE_NAME = 'E-restaurants-reviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_FILE_NAME, newline='') as dataFile:\n",
    "    dataTable = list(csv.reader(dataFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22666"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['review_id', 'date', 'text', 'stars', 'type', 'business_id'],\n",
       " ['H7eJZ9azd1eH5minOhc-uw',\n",
       "  '2008-07-06',\n",
       "  \"This Bar Restaurant is a wide open airy space within the Apex |International Hotel.We booked a table for Fathers Day Lunch. I have to say the food was excellent, the service was very good & value for money on the Sunay Lunch menu was excellent. The soup was piping hot, the Roast beef melted in the mouth! Didn't have room for puds but they looked fantastic\",\n",
       "  '5',\n",
       "  'review',\n",
       "  '-3pfhzz9CB7F2DpbF1Ko7Q']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTable[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "\n",
    "First we need to split the text into individual words. Merely splitting by white space is not sufficient, but we leave the details to NLTK.\n",
    "\n",
    "We also have to deal with capitalization (we don't want two different tags, _Restaurant_ and _restaurant_). For simplicity, we just lowercase all the text. True-caser or lemmatizer would be more appropriate, since _McDonald's_ looks better than _mcdonald's_ and _Apple_ means something else than _apple_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/eleanor/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install tokenizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [nltk.word_tokenize(text.lower()) for text in map(itemgetter(2), dataTable)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Had dinner here in december last year, it was close to my friends apt and we just went there because we didn't want to go far.\\nFood was nice, a bit pricey though, I had Orzo pasta, sun blushed tomato, rocket, parmesan & pine nuts, the pesto on it could've had less oil on it as I found quite greasy even for a pesto based sauce. It came with a nice salad so this was a good surprise. \\nWe had a nice rose wine and service was alright.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTable[3][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['had', 'dinner', 'here', 'in', 'december', 'last', 'year', ',', 'it', 'was']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bag-of-words representation\n",
    "\n",
    "Bag-of-words views text as a V-dimensional vector, where V is the size of vocabulary. Individual dimensions of vector can be set in various ways, one of the simplest is to use _v[i]_ = frequency of the word _i_ in the document. The corpus is then represented as a _DxV_ matrix where D is number of documents.\n",
    "\n",
    "In gensim, we use `Dictionary` to assign IDs to words, these IDs are then used as vector indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dictionary(51190 unique tokens: ['text', 'this', 'bar', 'restaurant', 'is']...)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = Dictionary(texts)\n",
    "\n",
    "str(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune dictionary\n",
    "\n",
    "Before we create the actual vectors, we can reduce dimensionality by removing non-informative words (prepositions etc.) and punctuation. Good heuristic is to remove words which are too common and words which are very rare (probably typos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/eleanor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stoplist = {'', ',', '.', '!', '?', ';', ':', '/', '\\'', '\\'s', '(', ')', '+', '-'}\n",
    "stoplist.update(stopwords.words('english'))\n",
    "stopIds = [tokId for tok, tokId in dictionary.token2id.items() if tok.lower() in stoplist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(51035 unique tokens: ['text', 'bar', 'restaurant', 'wide', 'open']...)\n",
      "Dictionary(24462 unique tokens: ['text', 'bar', 'restaurant', 'wide', 'open']...)\n"
     ]
    }
   ],
   "source": [
    "# remove stop words and very rare words\n",
    "dictionary.filter_tokens(bad_ids=stopIds)\n",
    "print(dictionary)\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.75, keep_n=None)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag-of-words representation\n",
    "docsBow = [dictionary.doc2bow(doc) for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsBow[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('quiffs', '..i')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[1716], dictionary[6805]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute TF-IDF\n",
    "\n",
    "We will use Gensim to compute TF-IDF for us. It will return the result as a matrix with same dimensions, but with different values. _m\\[d\\]\\[i\\]_ = TFIDF of word _i_ in document _d_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTfidf = TfidfModel(docsBow, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsTfidf = modelTfidf[docsBow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 0.9449252800474218),\n",
       " (17, 1.8945950048668478),\n",
       " (18, 1.1321541082717443),\n",
       " (19, 3.888926254780156),\n",
       " (30, 1.160472160469467)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsTfidf[3][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the tags\n",
    "\n",
    "Finally we can retrieve the tags for given document by selecting the words with the highest TF-IDF score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTags(doc, dictionary, count=5):\n",
    "    return [dictionary[id] for id, score in sorted(doc, key=itemgetter(1), reverse=True)][:count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"this bar restaurant is a wide open airy space within the apex |international hotel.we booked a table for fathers day lunch . i have to say the food was excellent , the service was very good & value for money on the sunay lunch menu was excellent . the soup was piping hot , the roast beef melted in the mouth ! did n't have room for puds but they looked fantastic\",\n",
       " ['fathers',\n",
       "  'apex',\n",
       "  'puds',\n",
       "  'piping',\n",
       "  'melted',\n",
       "  'airy',\n",
       "  'excellent',\n",
       "  'within'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(texts[1]), getTags(docsTfidf[1], dictionary, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"had dinner here in december last year , it was close to my friends apt and we just went there because we did n't want to go far . food was nice , a bit pricey though , i had orzo pasta , sun blushed tomato , rocket , parmesan & pine nuts , the pesto on it could 've had less oil on it as i found quite greasy even for a pesto based sauce . it came with a nice salad so this was a good surprise . we had a nice rose wine and service was alright .\",\n",
       " ['pesto', 'orzo', 'apt', 'blushed', 'pine', 'december', 'nuts', 'parmesan'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(texts[3]), getTags(docsTfidf[3], dictionary, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add bigrams\n",
    "\n",
    "Single-word tags are not quite enough. For some improvement, let's add bigrams which do not contain stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addBigrams(words, stoplist):\n",
    "    bigrams = ['_'.join(words[i:i + 2]) for i in range(len(words) - 1) \n",
    "               if words[i].lower() not in stoplist and words[i + 1].lower() not in stoplist]\n",
    "    return words + bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(307951 unique tokens: ['text', 'this', 'bar', 'restaurant', 'is']...)\n"
     ]
    }
   ],
   "source": [
    "docsTxtBi = [addBigrams(d, stoplist) for d in texts]\n",
    "dictionaryBi = Dictionary(docsTxtBi)\n",
    "print(dictionaryBi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(307796 unique tokens: ['text', 'bar', 'restaurant', 'wide', 'open']...)\n",
      "Dictionary(49897 unique tokens: ['text', 'bar', 'restaurant', 'wide', 'open']...)\n"
     ]
    }
   ],
   "source": [
    "stopIdsBi = [tokId for tok, tokId in dictionaryBi.token2id.items() if tok.lower() in stoplist]\n",
    "dictionaryBi.filter_tokens(bad_ids=stopIdsBi)\n",
    "print(dictionaryBi)\n",
    "dictionaryBi.filter_extremes(no_below=3, no_above=0.75, keep_n=None)\n",
    "print(dictionaryBi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsBowBi = [dictionaryBi.doc2bow(d) for d in docsTxtBi]\n",
    "modelTfidfBi = TfidfModel(docsBowBi, normalize=False)\n",
    "docsTfidfBi = modelTfidfBi[docsBowBi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"this bar restaurant is a wide open airy space within the apex |international hotel.we booked a table for fathers day lunch . i have to say the food was excellent , the service was very good & value for money on the sunay lunch menu was excellent . the soup was piping hot , the roast beef melted in the mouth ! did n't have room for puds but they looked fantastic\",\n",
       " ['day_lunch',\n",
       "  'bar_restaurant',\n",
       "  'apex',\n",
       "  'airy_space',\n",
       "  'good_&',\n",
       "  'puds',\n",
       "  'wide_open',\n",
       "  'looked_fantastic',\n",
       "  'roast_beef',\n",
       "  'piping_hot'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(texts[1]), getTags(docsTfidfBi[1], dictionaryBi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"had dinner here in december last year , it was close to my friends apt and we just went there because we did n't want to go far . food was nice , a bit pricey though , i had orzo pasta , sun blushed tomato , rocket , parmesan & pine nuts , the pesto on it could 've had less oil on it as i found quite greasy even for a pesto based sauce . it came with a nice salad so this was a good surprise . we had a nice rose wine and service was alright .\",\n",
       " ['pesto',\n",
       "  'blushed_tomato',\n",
       "  'less_oil',\n",
       "  'sun_blushed',\n",
       "  'parmesan_&',\n",
       "  'quite_greasy',\n",
       "  'orzo',\n",
       "  'found_quite',\n",
       "  'nice_salad',\n",
       "  'apt'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(texts[3]), getTags(docsTfidfBi[3], dictionaryBi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the 'pipeline' on previously unseen text\n",
    "\n",
    "Transform the text to a vector in our TF-IDF space and extract the highest scoring uni/bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to trasform plain text to a vector in our TF-IDF space\n",
    "def makeDoc(text, dictionary, stoplist, model):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    bow = dictionary.doc2bow(addBigrams(tokens, stoplist))\n",
    "    return model[bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(314, 3.1610413832193607),\n",
       " (436, 3.2551379727182637),\n",
       " (1374, 4.747143003652985),\n",
       " (9827, 10.298317190917858)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeDoc('I love cats. I make burgers out of them', dictionaryBi, stoplist, modelTfidfBi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'better_burgers'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionaryBi[19944]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glass',\n",
       " 'beautiful_inside',\n",
       " 'cocktail_prices',\n",
       " 'chandelier',\n",
       " 'mocktail',\n",
       " 'free_glass',\n",
       " 'guitar',\n",
       " 'souvenir',\n",
       " 'good_view',\n",
       " 'rock_cafe']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previously unseen text\n",
    "getTags(makeDoc('''Beautiful inside. Food was quick to come out. We had a good view of the bar from above and the gorgeous glass chandelier\n",
    "made into the shape of a guitar. Cocktail prices only showed it including the free glass \n",
    "which ends up meaning a mocktail costs you £12. So make sure you check out the smaller drinks menu \n",
    "at your table which shows the prices with or without the souvenir hard rock cafe glass. ''', \n",
    "                dictionaryBi, stoplist, modelTfidfBi), dictionaryBi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
