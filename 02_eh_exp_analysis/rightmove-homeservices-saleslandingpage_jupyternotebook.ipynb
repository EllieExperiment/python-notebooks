{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardised Experiment analysis example: My Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T09:35:04.906866Z",
     "start_time": "2021-04-27T09:35:02.032124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>code_show=true; function code_toggle(){if (code_show){$('div.input').hide();}else{$('div.input').show();}code_show=!code_show}$( document ).ready(code_toggle);</script>\n",
       "The raw code for this IPython notebook is by default hidden for easier reading. \n",
       "Raw code toggle: click <a href=\"javascript:code_toggle()\">here.</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import statsmodels.stats.power as smp\n",
    "from statsmodels.stats.power import NormalIndPower\n",
    "import nbconvert\n",
    "from IPython.display import HTML, display, Math, Latex, Image\n",
    "\n",
    "HTML('''<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>''')\n",
    "HTML('''\n",
    "<script>code_show=true; function code_toggle(){if (code_show){$('div.input').hide();}else{$('div.input').show();}code_show=!code_show}$( document ).ready(code_toggle);</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading. \n",
    "Raw code toggle: click <a href=\"javascript:code_toggle()\">here.</a>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: \n",
    "* Create a detailed write-up of how to analyse experiments statistically, \n",
    "* Explain the methods used in notebook markdown \n",
    "* Give commented versions the necessary python functions to show how to apply them.\n",
    "\n",
    "## 1.1 Your Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T09:39:24.751284Z",
     "start_time": "2021-04-27T09:39:24.747959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your experiment Name is: my_experiment\n",
      "Your experiment variants are: ['v1' 'v0']\n",
      "Your experiment launched on: 2020-01-02\n"
     ]
    }
   ],
   "source": [
    "#Configure this cell to read the experiment properties automatically\n",
    "print('Your experiment Name is: my_experiment')\n",
    "print(\"Your experiment variants are: ['v1' 'v0']\")\n",
    "print('Your experiment launched on: 2020-01-02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Experiment User Allocation\n",
    "When users are allocated to an experiment they are evenly split into groups or cohorts, depending on the number of variants in the experiment (v0, v1, v2 ... etc). Users will be distributed evenly between the variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Experiment User and Order Data  \n",
    "Query the following data to analyse the experiment overall by country and device  \n",
    "Fields:  \n",
    "* COUNT(has_order) as users  \n",
    "* SUM(has_order) as customers   \n",
    "* Grouped by:   variant_id, country, device  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T09:39:39.444625Z",
     "start_time": "2021-04-27T09:39:39.423468Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_df = pd.read_csv('exp_df_cr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T09:39:41.556339Z",
     "start_time": "2021-04-27T09:39:41.539655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>variant_id</th>\n",
       "      <th>users</th>\n",
       "      <th>customers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rightmove-homeservices-saleslandingpage</td>\n",
       "      <td>0</td>\n",
       "      <td>1950</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rightmove-homeservices-saleslandingpage</td>\n",
       "      <td>1</td>\n",
       "      <td>2053</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             experiment_id  variant_id  users  customers\n",
       "0  rightmove-homeservices-saleslandingpage           0   1950         11\n",
       "1  rightmove-homeservices-saleslandingpage           1   2053         20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Calculating the Success of an experiment variant\n",
    "The success is measured by looking at how well users in each variant convert.  \n",
    "This is done by calculating a proportion for each variant (or, in fact, the mean) that represents the sample of users in that variant, which we normally call Conversion Rate. For each variant, Conversion Rate is given by:\n",
    "\n",
    "$$CR_0 = \\frac{\\text{Number of Users Converting in cohort v0 within N Days}} {\\text{Number of Unique Users (UVs) in cohort v0}}$$\n",
    "\n",
    "Or: \n",
    "\n",
    "$$CR_0 = \\frac{\\text{Conversions_v0}} {\\text{UVs_v0}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Pyhton function for calculating Conversion Rate\n",
    "def var_cr(df):\n",
    "    conversions = float(sum(df.customers))\n",
    "    uvs = float(sum(df.users))\n",
    "    cr = float(conversions / uvs)\n",
    "    return cr\n",
    "# Returns the conversion rate from a given dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Calculate the Conversion Rates of this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant 0 Conversion Rate = 0.5599999999999999 %\n",
      "Variant 1 Conversion Rate = 0.97 %\n"
     ]
    }
   ],
   "source": [
    "print('Variant 0 Conversion Rate =',round(var_cr(exp_df[exp_df.variant_id==0]),4)*100,'%')\n",
    "print('Variant 1 Conversion Rate =',round(var_cr(exp_df[exp_df.variant_id==1]),4)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Hypothesis and measuring the success of an experiment\n",
    "Our hypothesis (H1) is that one variant will be more successful or less successful than another, which we will detect by observing a change in conversion rate for that group of users compared to a control group. This change in conversion rate is called \"uplift\" (also, the delta or effect size). \n",
    "\n",
    "To calculate the uplift in conversion rate we subtract the variant 1 conversion rate (v1) from the control conversion rate (v0), and divide by the v0 conversion to give the relative lift:\n",
    "\n",
    "$$\n",
    "Lift = \\frac{CR_1-CR_0}{CR_0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Python function for calculating lift between two variants, v0 and v1\n",
    "def exp_lift(df):\n",
    "    df_0 = df[df.variant_id==0]\n",
    "    df_1 = df[df.variant_id==1]\n",
    "    cr_0 = var_cr(df_0)\n",
    "    cr_1 = var_cr(df_1)\n",
    "    lift = (cr_1 - cr_0) / cr_0\n",
    "    return lift*100, cr_0, cr_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Calculate the Lift of this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant 1 Lift = 72.7 %\n"
     ]
    }
   ],
   "source": [
    "print('Variant 1 Lift =',round(exp_lift(exp_df)[0],2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Robust experimental approach\n",
    "In order to determine if the uplift observed in our sample of users is true, and we have not observed a difference between the two variants that isn't really there (eg noise in the data), we want to control for the likelihood of getting a false discovery (or Type 1 error).  \n",
    "* The probability of committing a Type I error is called the **significance level**, and is denoted by the symbol α.\n",
    "\n",
    "#### 1.4.1 Setting the alpha (α) or significance level\n",
    "The alpha sets the standard for how extreme the data must be before we can reject the null hypothesis. \n",
    "For example, if the alpha level is set at .05, this means we may reject the null only if the observed data are so unusual that they would have occurred by chance at most 5 % of the time.  \n",
    "* We set the value for the alpha before running each experiment, and the smaller the value of alpha the lower the false discovery rate (FDR) and the more robust the experiment result will be.\n",
    "\n",
    "#### 1.4.2 We do this by using an hypothesis test\n",
    "Hypothesis testing is a way for you to figure out if results from a test are valid or repeatable.  \n",
    "For example, if someone said they had found a new drug that cures cancer, you would want to be sure it was probably true. We use an hypothesis test to measure the likelihood that the observation (curing cancer in a drug trial with limited sample size) is likely to be true when applied to the larger population.  \n",
    "\n",
    "#### 1.4.3 Why use a Z-test?\n",
    "A Z-test is any statistical test for which the distribution of the test statistic under the null hypothesis can be approximated by a normal distribution (or Gaussian or Laplace–Gauss distribution).\n",
    "\n",
    "<img src=\"Normal_Distribution.png\" width=500 />\n",
    "\n",
    "In Experimentation, a Z-test is used because conversion is binomial and approximately normally distributed (Conversion is 0 if a Unique visitor visits but does not convert, or 1 if they visit and convert).\n",
    "\n",
    "The Z-test returns a Z-score which is the number of standard deviations below or above the population mean a measurement is. A z-score is also known as a standard score as it can be placed on a normal distribution curve. Z-scores are a way to compare results from a test to a “normal” population.\n",
    "\n",
    "#### 1.4.3 Calculating a Z-score\n",
    "The Z score for an experiment is given by the following formula for a two proportion hypothesis test:\n",
    "$$\n",
    "Z=\\frac{CR_0 - CR_1}{SE}\n",
    "$$\n",
    "\n",
    "Where $CR_0$ is the conversion rate of the control group (v0), $CR_1$ is the conversion rate of the variant group (v1), and SE is the pooled standard error, given by the following formula:\n",
    "$$\n",
    "SE = \\sqrt{se_0^2 + se_1^2}\n",
    "$$\n",
    "Where the standard error of variant 0 is:\n",
    "$$\n",
    "se_0 = \\frac{\\sigma_0}{\\sqrt n_0}\n",
    "$$\n",
    "And $\\sigma_0$ (sigma) is the standard deviation and $n_0$ is the number of users.\n",
    "$$\n",
    "\\sigma_0 =  \\sqrt{ \\sum CR_0(1-CR_0) }\n",
    "$$\n",
    "So that:\n",
    "$$\n",
    "se_0 = \\sqrt{  \\frac {CR_0(1-CR_0)} {\\sum n_0 } }\n",
    "$$\n",
    "\n",
    "Replacing into the formula for the z score this gives:\n",
    "$$\n",
    "Z=\\frac{CR_0 - CR_1}{\\sqrt{se_0^2 + se_1^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Pyhton function for calculating Standard Error\n",
    "\n",
    "def var_se(df):\n",
    "    se = float(np.sqrt(var_cr(df)*(1-var_cr(df)) / sum(df.users)))\n",
    "    return se\n",
    "\n",
    "# Example Pyhton function for calculating Z score\n",
    "\n",
    "def exp_z_score(df):\n",
    "    df_0 = df[df.variant_id==0]\n",
    "    df_1 = df[df.variant_id==1]\n",
    "    cr_0 = var_cr(df_0)\n",
    "    se_0 = var_se(df_0)\n",
    "    cr_1 = var_cr(df_1)\n",
    "    se_1 = var_se(df_1)\n",
    "    z_score = (cr_0 - cr_1) / (np.sqrt((se_0)**2 + (se_1)**2))\n",
    "    return z_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Reporting on the success of an experiment (or, can we reject the null hypothesis?)\n",
    "We convert the Z score to a p-value which gives a measurement of the strength of evidence in support of a null hypothesis:\n",
    "\n",
    "* If the p-value is **less than or equal** to the significance level or alpha **(p < α)**, then we reject the null hypothesis, and we say the **result is statistically significant**.\n",
    "* If the p-value is **greater than** alpha **(p > α)**, then we fail to reject the null hypothesis, and we say that the **result is statistically not significant**. \n",
    "\n",
    "P values are obtained using a table for converting the Z score to a p value (http://www.z-table.com/), which can be done easily in code in python or R using the right command/package: p_value = stats.norm.sf(abs(z_score))*2\n",
    "\n",
    "### 1.5.1 Experiment Confidence level or p-value\n",
    "Having obtained a p-value for the experiment, this is normally converted to a \"confidence level\" to ease communication of the result, by subtracting the p value from 1, like this:\n",
    "$$\n",
    "p = 0.17\n",
    "$$\n",
    "$$\n",
    "Confidence = (1-0.17)\\cdot100 = 83\\%\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "confidence = (1- alpha)*100\n",
    "\n",
    "def exp_pvalue(z_score):\n",
    "    p_value = stats.norm.sf(abs(z_score))*2\n",
    "    return p_value\n",
    "\n",
    "def exp_significant(p):\n",
    "    if p <= alpha: \n",
    "          print('Expriment variant is Significant \\n')\n",
    "    else:\n",
    "          print('Expriment variant is NOT Significant\\n')\n",
    "            \n",
    "def experiment_overview(df):  \n",
    "    lift = exp_lift(df)[0]\n",
    "    z_score = exp_z_score(df)\n",
    "    p_value = exp_pvalue(exp_z_score(df))\n",
    "    cr_0 = exp_lift(df)[1]\n",
    "    cr_1 = exp_lift(df)[2]\n",
    "    nobs1 = exp_df[exp_df.variant_id==0].users\n",
    "    #significant = exp_significant(p_value)\n",
    "    output = [round(cr_0,5), round(cr_1,5), \n",
    "          round(z_score,5), round(p_value,5), \n",
    "          round((1-p_value)*100,2), round(lift, 5), nobs1]\n",
    "    df_cr = pd.DataFrame([output])\n",
    "    df_cr.columns = ['CR Control', 'CR Contender','z-score', 'P-value', 'Significance', 'Lift','nobs1']\n",
    "    return df_cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 Calculating the Experiment confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Variant 1 Confidence = 86.0 %\n"
     ]
    }
   ],
   "source": [
    "exp_overview_df = experiment_overview(exp_df)\n",
    "print('Experiment Variant 1 Confidence =',round(exp_overview_df['Significance'][0],0),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: \n",
    "* Explore methods for calculating margin of error for each conversion rate in an experiment \n",
    "* Use those intervals to create intervals for the experiment uplift, such that when an experiment reaches 90% confidence, the intervals can be used to report on the experiment result intuitively \n",
    "\n",
    "\n",
    "### Part 2: Using Margin of error to simplify experiment reporting\n",
    "\n",
    "#### 2.1 What is Margin of Error?\n",
    "\n",
    "A margin of error tells you how many percentage points your results will differ from the real population value. For example, a 95% confidence interval with a 4 percent margin of error means that your statistic will be within 4 percentage points of the real population value 95% of the time.  \n",
    "\n",
    "The Margin of Error can be calculated by:  \n",
    "\n",
    "* Margin of error = Critical Z value x Standard error of the statistic\n",
    "\n",
    "And as we have already calculated the Standard Error for each variant, this just means we need to calculate the Critical Z Value for the confidence interval of interest.\n",
    "\n",
    "#### 2.2 What is the critical value? \n",
    "The critical value is the Z score for a specific p-value (or confidence interval), and is given by $Z_c$.\n",
    "In this case we want the Z score for a p-value of 0.1, given the the alpha or significane level we set before running the experiment. This will therefore give margin or error for the 90% confidence interval once calculated ( as Confidence = (1-p) ).\n",
    "\n",
    "Therefore:\n",
    "$$\n",
    "    p_c = 0.1\n",
    "$$\n",
    "$$\n",
    "    Z_c = stats.norm.ppf(p_c) = stats.norm.ppf(0.1)\n",
    "$$\n",
    "Thus:\n",
    "$$\n",
    "    Z_c = 1.2815515655446004\n",
    "$$\n",
    "\n",
    "Having obtained the required Z_critical, we now have everything we need to calculate the Margin of Error for the 90% confidence interval:\n",
    "\n",
    "$$\n",
    "ME_0= Z_c \\cdot \\frac{CR_0 - CR_1}{\\sqrt{se_0^2 + se_1^2}}\n",
    "$$\n",
    "\n",
    "And as:\n",
    "$$\n",
    "se_0 = \\sqrt{  \\frac {CR_0(1-CR_0)} {\\sum n_0 } }\n",
    "$$\n",
    "\n",
    "This gives:\n",
    "$$\n",
    "ME_0= Z_c \\cdot se_0\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_critical(df):\n",
    "    df_0 = exp_df[exp_df.variant_id==0]\n",
    "    df_1 = exp_df[exp_df.variant_id==1]\n",
    "    cr_0 = var_cr(df_0)\n",
    "    se_0 = var_se(df_0)\n",
    "    cr_1 = var_cr(df_1)\n",
    "    se_1 = var_se(df_1)\n",
    "    p_critical = alpha\n",
    "    z_score_critical = abs(stats.norm.ppf(abs(p_critical/2)))\n",
    "    return z_score_critical, se_0, se_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant 0 Conversion Rate = 0.56 %\n",
      "Variant 1 Conversion Rate = 0.97 %\n",
      "Variant 0 Standard Error = 0.17\n",
      "Variant 1 Standard Error = 0.22\n"
     ]
    }
   ],
   "source": [
    "print('Variant 0 Conversion Rate =',round(var_cr(exp_df[exp_df.variant_id==0])*100,2),'%')\n",
    "print('Variant 1 Conversion Rate =',round(var_cr(exp_df[exp_df.variant_id==1])*100,2),'%')\n",
    "print('Variant 0 Standard Error =',round(var_se(exp_df[exp_df.variant_id==0])*100,2))\n",
    "print('Variant 1 Standard Error =',round(var_se(exp_df[exp_df.variant_id==1])*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_of_error_0 = exp_critical(exp_df)[0] * exp_critical(exp_df)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_of_error_1 = exp_critical(exp_df)[0] * exp_critical(exp_df)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant 0 Margin of Error = 0.279 %\n",
      "Variant 1 Margin of Error = 0.357 %\n"
     ]
    }
   ],
   "source": [
    "print('Variant 0 Margin of Error =',round(margin_of_error_0*100,3),'%')\n",
    "print('Variant 1 Margin of Error =',round(margin_of_error_1*100,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 How do we use it to calculate Lift intervals?\n",
    "To estimate a difference in population proportions (or a treatment effect), the statistic is a difference in sample proportions. So the confidence interval is\n",
    "\n",
    "$$\\textrm { Confidence Interval = sample statistic } \\pm \\textrm{ Margin of error} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Calculate the Confidence interval of each conversion rate\n",
    "* The confidence interval for each conversion rate is given by \n",
    "\n",
    "Upper Confidence Interval for $CR_0$ = \n",
    "$$\n",
    "CI_{0\\_Upper} = CR_0 + ME_0\n",
    "$$\n",
    "\n",
    "Upper Confidence Interval for $CR_0$ = \n",
    "$$\n",
    "CI_{0\\_Lower} = CR_0 - ME_0\n",
    "$$\n",
    "\n",
    "* This is then repeated for the other variant, leading to 4 calculated intervals in total (two upper, two lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_0 = (var_cr(exp_df[exp_df.variant_id==0]) - margin_of_error_0,\n",
    "                       var_cr(exp_df[exp_df.variant_id==0]) + margin_of_error_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_1 = (var_cr(exp_df[exp_df.variant_id==1]) - margin_of_error_1,\n",
    "                       var_cr(exp_df[exp_df.variant_id==1]) + margin_of_error_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant 0 Lower Interval = 0.29 %\n",
      "Variant 0 Upper Interval = 0.84 %\n",
      "Variant 1 Lower Interval = 0.62 %\n",
      "Variant 1 Upper Interval = 1.33 %\n"
     ]
    }
   ],
   "source": [
    "print('Variant 0 Lower Interval =',round(confidence_interval_0[0]*100,2),'%')\n",
    "print('Variant 0 Upper Interval =',round(confidence_interval_0[1]*100,2),'%')\n",
    "print('Variant 1 Lower Interval =',round(confidence_interval_1[0]*100,2),'%')\n",
    "print('Variant 1 Upper Interval =',round(confidence_interval_1[1]*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Calculate the Lift Intervals:\n",
    "* Calculate the upper and lower values the lift could take based on the conversion rate confidence intervals\n",
    "\n",
    "And as:\n",
    "$$\n",
    "Lift = \\frac{CR_1-CR_0}{CR_0}\n",
    "$$\n",
    "\n",
    "Lift Upper Bound = \n",
    "$$\n",
    "Lift_{Upper} = \\frac{CI_{1\\_Upper}-CI_{0\\_Lower}}{CI_{0\\_Lower}}\n",
    "$$\n",
    "\n",
    "Lift Lower Bound = \n",
    "$$\n",
    "Lift_{Lower} = \\frac{CI_{1\\_Lower}-CI_{0\\_Upper}}{CI_{0\\_Upper}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_upper = ((confidence_interval_1[1] - confidence_interval_0[0]) / confidence_interval_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_lower = ((confidence_interval_1[0] - confidence_interval_0[1]) / confidence_interval_0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lift Upper Interval = 366.71 %\n",
      "Lift Lower Interval = -26.74 %\n"
     ]
    }
   ],
   "source": [
    "print('Lift Upper Interval =',round(lift_upper*100,2),'%')\n",
    "print('Lift Lower Interval =',round(lift_lower*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Raw code toggle: click <a href=\"javascript:code_toggle()\">here.</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''Raw code toggle: click <a href=\"javascript:code_toggle()\">here.</a>''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
